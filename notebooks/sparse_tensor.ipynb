{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86372ae-a079-4b37-9b46-8d6eeec6bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96767e4e-67e8-4183-9233-36741fa9485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sparse(x):\n",
    "    nz = np.where(np.logical_not(np.isclose(x.numpy(), 0)))\n",
    "    sparse_x = T.sparse_coo_tensor(nz, x[nz], size=x.size(), dtype=T.float32)\n",
    "    \n",
    "    return sparse_x\n",
    "\n",
    "\n",
    "class SparseTensorDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        assert len(X) == len(Y)\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.Y[idx]\n",
    "        \n",
    "        sparse_x = make_sparse(x)\n",
    "        \n",
    "        return (sparse_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ed6f8af-191f-47c0-976b-e76cdfee9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(input_size, output_size),\n",
    "        )\n",
    "    \n",
    "    def forward(self, sx):\n",
    "        return T.sigmoid(self.seq(sx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c8ad51-af65-4d20-a4ba-7a5f3c0dc6be",
   "metadata": {},
   "source": [
    "### 1. Using `SparseTensor` out-of-the-box\n",
    "\n",
    "This will raise:\n",
    "```\n",
    "NotImplementedError: Cannot access storage of SparseTensorImpl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a06062f-7a08-4d23-8169-a11758ca1fb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Caught NotImplementedError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/alex/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/alex/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/alex/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/alex/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/alex/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 54, in default_collate\n    storage = elem.storage()._new_shared(numel)\nNotImplementedError: Cannot access storage of SparseTensorImpl\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/tmp/ipykernel_11262/363478487.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1201\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1229\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/miniconda3/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;31m# have message field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Caught NotImplementedError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/alex/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/alex/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/alex/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/alex/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/alex/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 54, in default_collate\n    storage = elem.storage()._new_shared(numel)\nNotImplementedError: Cannot access storage of SparseTensorImpl\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "M = 32\n",
    "\n",
    "X = T.rand(N, M)\n",
    "Y = T.randint(0, 2, size=(N,))\n",
    "\n",
    "ds = SparseTensorDataset(X, Y)\n",
    "dl = DataLoader(ds, batch_size=4, shuffle=False, pin_memory=True, num_workers=2)\n",
    "\n",
    "for batch_idx, (sx, y) in enumerate(dl):\n",
    "    print(sx, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17cc578-7a02-418a-943f-82490f2fc791",
   "metadata": {},
   "source": [
    "### 2. Using `SparseTensor` without multiprocessing and memory pinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5077695b-7942-4310-af5d-fa4f9c7a82ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_idx=60 | lr=[0.0005] | avg_loss=0.04111\r"
     ]
    }
   ],
   "source": [
    "N = 1024 * 20\n",
    "M = 8\n",
    "\n",
    "X = T.rand(N, M) * T.randint(0, 2, size=(N, M))\n",
    "Y = (X.sum(dim=-1) < 2).to(T.float32)\n",
    "\n",
    "ds = SparseTensorDataset(X, Y)\n",
    "dl = DataLoader(ds, batch_size=256, shuffle=False, pin_memory=False, num_workers=0)\n",
    "\n",
    "net = Net(input_size=M, output_size=1)\n",
    "loss_crit = nn.BCELoss()\n",
    "optimizer = T.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001)\n",
    "scheduler = T.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "avg_loss = 0\n",
    "\n",
    "net.cuda()\n",
    "\n",
    "for epoch_idx in range(1, 60 + 1):\n",
    "    \n",
    "    for batch_idx, (sx, y) in enumerate(dl, start=1):\n",
    "        sx, y = sx.cuda(), y.cuda()\n",
    "        \n",
    "        # print(f\"{sx=}\")\n",
    "        # print('-' * 128)\n",
    "        # print(f\"{y=}\")\n",
    "\n",
    "        # print('-' * 128)\n",
    "\n",
    "        y_pred = net(sx)\n",
    "        # print(f'{y_pred=}')\n",
    "\n",
    "        # print('-' * 128)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_crit(y_pred.to(T.float32), y.unsqueeze(1).to(T.float32))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss.item() / len(dl)\n",
    "    # ---\n",
    "\n",
    "    print(f'{epoch_idx=:2d} | lr={scheduler.get_last_lr()} | avg_loss={loss.item():.5f}', end='\\r')\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5aedb51-dd33-47e9-954b-78fe11b8afb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9930]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
       " tensor([[0.9930]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
       " True)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.rand(1, M) * T.randint(0, 2, size=(1, M))\n",
    "true = (x.sum(dim=-1) < 2).item()\n",
    "\n",
    "net(x.cuda()), net(make_sparse(x).cuda()), true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcceefc0-934e-4bae-ae03-d04f133b5c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
